# Code Optimization Best Practices
At this point we're going to talk about the best practices for optimize the code.

## Index

* [Introduction](#introduction)
* [Concepts](#concepts)
	* [O Notation](#o-notation)
	* [Unnecesary code](#unnecesary-code)
* [Simple Data Structures](#simple-data-structures)
	* [Route](#route)
	* [Searching](#searching)
	* [Ordering](#ordering)
	* [Constants propagation](#constants-propagation)
* [Recursivity](#recursivity)
* [Complex Data Structures](#complex-data-structures)
	* [Hash tables](#hash-tables)
	* [Trees](#trees)
	* [Graphs](#graphs)
* [Profiling](#profiling)
	* [Profilers types depending on the response](#profilers-types-depending-on-the-response)
	* [Granularity](#granularity)
	* [Statistic's profilers](#statistics-profilers)
* [Instrumentation](#instrumentation)
* [Loop Optimization](#loop-optimization)
  * [Common Tips](#common-tips)
  * [Optimization via a sequence of loop transformations](#optimization-via a-sequence-of-loop-transformations)
    * [Common transformations](#common-transformations)
    * [Other transformations](#other-transformations)
  * [The unimodular transformation framework](#the-unimodular-transformation-framework)
  * [The polyhedral or constraint-based framework](#the-polyhedral-or-constraint-based-framework)
* [Efficient Exceptions Management](#efficient-exceptions-management)
* [Tools](#tools)
	* [Loggers](#loggers)
	* [Dead code detection](#dead-code-detection)
* [References](#references)

## Introduction

## Concepts

### O Notation

### Unnecesary code

## Simple Data Structures

### Route

### Searching

### Ordering

### Constants propagation

## Recursivity

## Complex Data Structures

### Hash tables

### Trees

### Graphs

## Profiling

### Profilers types depending on the response

### Granularity

### Statistic's profilers

## Instrumentation

## Loop Optimization
Loop optimization is the process of the increasing execution speed and reducing the overheads associated of loops. As the most execution time of a application is spent on loops,  a lot of optimization techniques have been developed to make them faster.

### Common tips

* Try to avoid ending conditions of loops with unnecessary calculations, because its will be calculated in each loop iteration.
* By the same reason, is interesting initialize the common variables out of the loop.

### Optimization via a sequence of loop transformations
Loop optimization can be defined like the application of a sequence of loop transformations. A transformation or sequence of them must preserve the temporal sequence of all dependencies to preserve the result of the application. Is difficult to evaluate the benefits of a transformations and the use of one beneficial transformation may require to use of other transformations that by themselves may result in reduced performance.

#### Common transformations

* **[fission/distribution](https://en.wikipedia.org/wiki/Loop_fission)**: Attempts to break a loop into multiple loops over the same index range but each taking only a part of the loop's body. This can improve locality of reference, both of the data being accessed in the loop and the code in the loop's body.
* **[fusion/combining](https://en.wikipedia.org/wiki/Loop_fusion)**: Attempts to reduce loop overhead. When two adjacent loops would iterate the same number of times (whether or not that number is known at compile time), their bodies can be combined as long as they make no reference to each other's data.
* **[interchange/permutation](https://en.wikipedia.org/wiki/Loop_interchange)**: Exchanges inner loops with outer loops. When the loop variables index into an array, such a transformation can improve locality of reference, depending on the array's layout.
* **[inversion](https://en.wikipedia.org/wiki/Loop_inversion)**: Changes a standard while loop into a do/while (repeat/until) loop wrapped in an if conditional, reducing the number of jumps by two for cases where the loop is executed. Doing so duplicates the condition check (increasing the size of the code) but is more efficient because jumps usually cause a pipeline stall. Additionally, if the initial condition is known at compile-time and is known to be side-effect-free, the if guard can be skipped.
* **[loop-invariant code motion](https://en.wikipedia.org/wiki/Loop-invariant_code_motion)** : If a quantity is computed inside a loop during every iteration, and its value is the same for each iteration, it can vastly improve efficiency to hoist it outside the loop and compute its value just once before the loop begins. This is particularly important with the address-calculation expressions generated by loops over arrays. For correct implementation, this technique must be used with loop inversion, because not all code is safe to be hoisted outside the loop.
* **[parallelization](https://en.wikipedia.org/w/index.php?title=Loop_parallelization&action=edit&redlink=1)**: A special case for automatic parallelization focusing on loops, restructuring them to run efficiently on multiprocessor systems. It can be done automatically by compilers (named automatic parallelization) or manually (inserting parallel directives like OpenMP).
* **[reversal](https://en.wikipedia.org/w/index.php?title=Loop_reversal&action=edit&redlink=1)**: Reverses the order in which values are assigned to the index variable. This is a optimization which can help eliminate dependencies and thus enable other optimizations. Also, certain architectures utilize looping constructs at assembly language level that count in a single direction only (e.g. decrement-jump-if-not-zero (DJNZ)).
* **[scheduling](https://en.wikipedia.org/wiki/Loop_scheduling)**: Divides a loop into multiple parts that may be run concurrently on multiple processors.
* **[skewing](https://en.wikipedia.org/wiki/Loop_skewing)**: Loop skewing takes a nested loop iterating over a multidimensional array, where each iteration of the inner loop depends on previous iterations, and rearranges its array accesses so that the only dependencies are between iterations of the outer loop.
* **[software pipelining](https://en.wikipedia.org/wiki/Software_pipelining)**: A type of out-of-order execution of loop iterations to hide the latencies of processor function units.
* **[splitting/peeling](https://en.wikipedia.org/wiki/Loop_splitting)**: Loop splitting attempts to simplify a loop or eliminate dependencies by breaking it into multiple loops which have the same bodies but iterate over different contiguous portions of the index range. A useful special case is loop peeling, which can simplify a loop with a problematic first iteration by performing that iteration separately before entering the loop.
* **[tiling/blocking](tiling/blocking)**: Loop tiling reorganizes a loop to iterate over blocks of data sized to fit in the cache.
* **[vectorization](https://en.wikipedia.org/wiki/Automatic_vectorization)**: Attempts to run as many of the loop iterations as possible at the same time on a multiple-processor system.
* **[unrolling](https://en.wikipedia.org/wiki/Loop_unrolling)**: Duplicates the body of the loop multiple times, in order to decrease the number of times the loop condition is tested and the number of jumps, which may degrade performance by impairing the instruction pipeline. Completely unrolling a loop eliminates all overhead (except multiple instruction fetches & increased program load time), but requires that the number of iterations be known at compile time. Care must also be taken to ensure that multiple re-calculation of indexed variables is not a greater overhead than advancing pointers within the original loop.
* **[unswitching](https://en.wikipedia.org/wiki/Loop_unswitching)**: Moves a conditional inside a loop outside of it by duplicating the loop's body, and placing a version of it inside each of the if and else clauses of the conditional.

#### Other transformations

* **[sectioning](https://en.wikipedia.org/w/index.php?title=Loop_sectioning&action=edit&redlink=1)**: The loop-sectioning (also called strip-mining) is a loop-transformation technique for enabling SIMD-encodings of loops and improving memory performance. This technique involves each vector operation being done for a size less than or equal to the maximum vector length on a given vector machine.

### The unimodular transformation framework

The unimodular transformation approach uses a single unimodular matrix to describe the combined result of a sequence of many of the above transformations. Central to this approach is the view of the set of all executions of a statement within n loops as a set of integer points in an n-dimensional space, with the points being executed in lexicographical order. For example, the executions of a statement nested inside an outer loop with index i and an inner loop with index j can be associated with the pairs of integers (i, j). The application of a unimodular transformation corresponds to the multiplication of the points within this space by the matrix.

A unimodular transformation is legal if it preserves the temporal sequence of all dependencies; measuring the performance impact of a unimodular transformation is more difficult. Imperfectly nested loops and some transformations (such as tiling) do not fit easily into this framework.

### The polyhedral or constraint-based framework

The polyhedral model handles a wider class of programs and transformations than the unimodular framework. The set of executions of a set of statements within a possibly imperfectly nested set of loops is seen as the union of a set of polytopes representing the executions of the statements. Affine transformations are applied to these polytopes, producing a description of a new execution order. The boundaries of the polytopes, the data dependencies, and the transformations are often described using systems of constraints, and this approach is often referred to as a constraint-based approach to loop optimization. For example, a single statement within an outer loop 'for i := 0 to n' and an inner loop 'for j := 0 to i+2' is executed once for each (i, j) pair such that 0 <= i <= n and 0 <= j <= i+2.

You can find more information at [Wikipedia](https://en.wikipedia.org/wiki/Loop_optimization).

## Efficient Exceptions Management
The exception management may be performance expensive, is better write proactive code which verifies some conditions that eventually may produces exceptions. There are some examples for this:

* If you need divide by a variable, is more efficient test if the divider is 0 than management an exception.
* Also is better test a correct format for a variable than make a cast and catch the error.

## Tools

### Loggers
All programming languages have systems to print information, but in the most of cases isn't efficient use it for print information, because these operations are synchronous and slow. Each programming language have its own libraries to process log messages and allows to save it at disk and/or screen and configure a determined format. Its very recommended use these libraries for improve the performance and manage the log levels unifying the log styles.

For improve the performance of your application is recommended that in production environments only show logs with level INFO, WARN and ERROR. For this goal its important that when you develop your application and you want to log something think about if is usefull information and if is better use debug or info level. Try to avoid print large objects or huge amount information if isn't really necesary, this type of information may be usefull when you are trying your code in local mode or development environments, but in production environments normally penalize the performance and complicate the understanding or reading of the logs.

### Dead code detection
Dead code is also called unreachable code and is a part of a source code of a program which never is called for others parts of the application or which actions has not any effect. Its recommended to avoid to have dead code for some reasons:

* Ocuppies unnecessary memory.
* Causes unnecessary caching of instructions into the CPU instruction cache - which also decreases data locality.
* From the perspective of program maintenance; time and effort may be spent maintaining and documenting a piece of code which is in fact unreachable, hence never executed.

Some tools can you help to discover the dead code and remove it in all programming languages. There are some of them:

* **Java**:
  * For dynamic code analysis exists a tool [Cobertura](http://cobertura.github.io/cobertura/) that is easy to configure in maven and Jenkins tools.
  * [UCDetector](http://www.ucdetector.org/) is a Eclipse Plugin to find unnecesary public java code like classes methods or fields which have no references.
* **Python**: [coverage.py](http://coverage.readthedocs.org/en/latest/) is a dynamic code analyzer thats call the code to detect unreachable code.
* **JavaScript**: There are some tools that help to detect unreachable code:
  * [JSHint](http://jshint.com/about/) is a static code analysis tool for JavaScript.
  * [Closure](https://developers.google.com/closure/compiler/) is a compiler for JavaScript that parses your JavaScript, analyzes it, removes dead code and rewrites and minimizes what's left. It also checks syntax, variable references, and types, and warns about common JavaScript pitfalls.



### References

* [Link](http://www.url.to) Description
* [oficialsite.org](http://www.oficialwebsite.org) API & Docs
* [Overapi Cheatsheet](http://overapi.com/example/) Cheatsheet

___

[BEEVA](http://www.beeva.com) | 2015
