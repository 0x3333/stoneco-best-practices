![alt text](static/mongodb-logo.png "MongoDB")

# MongoDB Best Practices

## Index

* [Introduction](#introduction)
* [Best Practices](#best-practices)
* [Storage engine] (#storage-engine)
* [CRUD] (#crud)
* [References](#references)

## Introduction

MongoDB is an open-source document database that provides high performance, high availability, and automatic scaling.

A record in MongoDB is a document, which is a data structure composed of field and value pairs. The values of fields may include other documents, arrays, and arrays of documents.

The advantages of using documents are:
* Documents (i.e. objects) correspond to native data types in many programming languages.
* Embedded documents and arrays reduce need for expensive joins.
* Dynamic schema supports fluent polymorphism.

Documents are stored in collections. A collection in MongoDb is comparable to a table in a relational database, with the difference that the documents in a collection does not need to have the same scema.

Every document has the field "_id". If this field is not provided by the user, it will be automatically generated.

## Best Practices

### Create indexes

One of the most important things in any data base system are indexes. They are very important to improve query performance, so indexes should be created to support queries.
On the other hand, indexes spend space and, more important, maintaining much indexes makes lower inserting performance, so don’t create indexes that queries do not use.

MongoDb always create a default unique _id index for every collection. This index cannot be dropped.

When you create indexes you can define order ascending or descending. Next index types are supported:
* __Single field__: an index over a single field of the documents.
* __Compound index__: an index over multiple fields. The order can be defined for each of the fields.
* __Multikey index__: a special type of index generated by MongoDb when you create an index where at least one field is an array.
* __Geospatial index__: index for geospatial coordinate data. MongoDB support 2 types of geospatial index:
..* _2d index_ uses planar geometry. You can find more information about this type of index [here](https://docs.mongodb.com/manual/core/2d/)
..* _2dsphere index_ uses spherical geometry. You can find more information about this type of index [here](https://docs.mongodb.com/manual/core/2dsphere/)
* __Text index__: index to support text queries over string content. It does not store language-specific stop words like “the”, “a”, “or”, etc.
* __Hashed index__: indexes the hash of the value of a field instead the value itself. Due to their nature, these indexes only support equality matches and cannot support range-based queries.

Moreover, indexes can have special properties:
* __Unique__: If an index is defined as unique, duplicate values for the indexed field will be rejected.
* __Sparse__: If an index is defined as sparse, it will skip documents that do not have the indexed field .
* __TTL__: It will remove documents from a collection after a certain amount of time.

When you create indexes, you must keep in mind the next limitations:
* A single collection can have no more than 64 indexes.
* Fully qualified index names, which includes the namespace and the dot separators (i.e. __<database name>.<collection name>.$<index name>__), cannot be longer than 128 characters.
* There can be no more than 31 fields in a compound index.
* Queries cannot use both text and Geospatial Indexes.
* Fields with 2dsphere Indexes can only hold Geometries.
* For a compound multikey index, each indexed document can have at most one indexed field whose value is an array. As such, you cannot create a compound multikey index if more than one to-be-indexed field of a document is an array. Or, if a compound multikey index already exists, you cannot insert a document that would violate this restriction. So be careful with it.
* The total size of an index entry must be less than 1024 bytes.

### Always use replica sets

A replica set in MongoDB is a group of mongod processes that maintain the same data set. 
Replication provides high availability of your data if node fails in your cluster. Replica Set provides automatic failover mechanism. If your primary node fails, a secondary node will be elected as primary and your cluster will remain functional. 
In some cases, replication can provide increased read capacity as clients can send read operations to different servers.
In a replica set there always is a primary node that receives write operations and some secondaries that replicate the data thorught an oplog, applying operations asynchronously.
You should replicate with at least 3 nodes in any MongoDB deployment.

If the primary node goes down, a secondary must be elected to be the new primary. This is done with an election where each node emites a vote. Therefore, it is highly recommended to have an odd number of nodes.
If you have an even number of nodes in your replica set, and you do not want to increase your hardware for break down elections, use an arbiter node. An arbiter is a node of the replica set that do not maintain data but takes part in the election. An arbiter do not maintain data, so it is not elegible to be the primary, thus you do not need a great hardware on it.
Anyway, remember that, although a replica set can have up to 50 members (12 members before version 3.0), there can be no more than seven voting members in a replica set.

In any cases you may want to have secondary nodes in a replica set that are not be able to convert to primary members. In these cases yo must set priority 0 for those nodes.

Aditionally, you could want to have some special node for dedicated task. In this case you should also mark the node as hidden. Doing it, you maintain that node invisible to client applications. Furthermore, in a sharded cluster, balancers do not interact with hidden members. So a hidden member will not receive read operations.
This is an example of hidding the member at the index 0 in the members array of a replica set:
```javascript
cfg = rs.conf()
cfg.members[0].priority = 0
cfg.members[0].hidden = true
rs.reconfig(cfg)
```

Often, human errors take place. To help to recover these errors when they are detected in a reasonable time, you can set a delayed member in your replica set.
A delayed member is a hidden member that apply de oplog operations with a delay. Therefore you could recover from it the data that you had in realtime nodes the "delayed" time ago.
So, you should apply big enought delay to your expected recover or maintenance duration. On the other hand, the delay must not be big enought to exceed the capacity of the oplog.
Nevertheless, delayed members are not recommended in sharded clusters because of the possible chunk migrations during the delay. 

### Your working set should fit in memory

The working set is the set of data and indexes accessed during normal operations. Proper capacity planning is important for a highly performant application
Being able to keep the working set in memory is an important factor in overall cluster performance.
MongoDB works best when the data set can reside in memory. Nothing performs better than a MongoDB instance that does not require disk I/O. 
Whenever possible select a platform that has more available RAM than your working data set size.

If you notice the number of page faults increasing, there is a very high probability that your working set is larger than your available RAM.
When this happens, you should increase your instance RAM size. If you can do it, consider using sharding to increase the amount of available RAM in a cluster.

### Scale up if your metrics show heavy use

If your instance shows a load over 60% - 65%, you should consider scaling up. Your load should be consistently below this threshold during normal operations. This also impacts recovery and vertical scaling scenarios.
At the moment you identify that you wanted to scale, you should consider sharding. By sharding, MongoDB distributes the data across sharded cluster.

### When to shard

In addition to mentioned previously, you should consider sharding if you anticipate a large data set.
Sharding may also help write performance so it is also possible that you may elect to shard even if your data set is small but requires a high amount of updates or inserts.

However, sharding may not be the solution to a bad performance. If you have worse performance than expected, you should reconsider your schema and indexes.

When you decide to shard, a very important decision you maust take is the choice of the shard key, since the distribution of the data will depend on it, and affects the overall efficiency and performance of operations within the sharded cluster. 
Furthermore shard key is inmutable, so once you create a shard key you will not be able to change it.

To shard a collection use the method `sh.shardCollection()` specifying the target collection and the shard key.
All sharded collections must have an index that supports the shard key; i.e. the index can be an index on the shard key or a compound index where the shard key is a prefix of the index. So if you want to shard a non empty collection, you previously must create the index. However, if the collection is empty, the index will be created if it does not exist.

The choice of a shard key will depend on your data and their nature. Based on it, you should keep in mind some important criteria.

The first (and obvious) consideration is that every document in the collection must contain the fields that be part of the shard key, otherwise it would be impossible to know where the document should be localized.

For the choice of the shard key, you will have to consider the importance of distribuiton of data, write performance and read performance, and which is more important to you. Depending on it, to choose a shard key as good as possible try to:
* Create a shard key easily divisible. For it, consider fields (or combination of fields) that can take a large number of distinct values, and that are not expected to have the same value in many different documents. This will provide distribution of data.
* Create a shard key with high degree of randomness. In this way write operations will be distributed among the cluster, preventing that a single shard becomes a bottleneck. This will provide write performance.
..* Do not create monotonically changing shard key. A shard key on a value that always increases or that always decreases is more likely to distribute inserts to a single shard within the cluster, becoming it a bottleneck.
..* If the nature of your data makes dificult to choose an enought random shard key or you are considering to select a monotically changing field because of other selecting criteria, you may consider to use a hashed index for the shard key. In this case you can only use a single field. 
* Create a shard key that targets a single shard. Thus, balancer can easily redirect queries to specific shard. This will provide read performance.
* Create a shard key based on a compound index. Selecting a group of fields as the shard key instead of a single field, will facilitate you to get a more ideal shard key.
 
In addition, whe you are going to create the shard key, you must keep in mind the next limitations:
* If the shard key index is not a hasehd index, then the index, or the prefix part of the index corresponding to shard key must have ascending order.
* A shard key index cannot be an index that specifies a multikey index, a text index or a geospatial index on the shard key fields.
* As mentioned, shard key is inmutable.
* Shard key value in a document is inmutable, this is, you cannot update the values of the shard key fields.
* A shard key cannot exceed 512 bytes.


### Keep each mongo instance on its own machine

Mongo instances always try to use as resources as it can. So you should not run more than one instance on the same machine.
If you run more than one mongo instance in a single machine, all of that instances will fight for the same resources.
...

### Turn journaling on by default

MongoDB supports write-ahead journaling of operations to facilitate crash recovery and node durability.
Journaling basically holds write-ahead redo logs, in the event of crash, the journal files will be used for recovery and this enables data consistency and durability.
Journal process differs depending on storage engine. Journaling is recommended storage engines that make use of disk, like MMAPv1 or the newer WiredTiger.
Nevertheless, for the new In-Memory Storage Engine of MongoDB Enterprise version 3.2.6, there is no separate journal, because its data is kept in memory.

### Hardware

#### Don't run MongoDB on 32-bit systems
MongoDB has a 2GB data limit on 32-bit system and 32-bit systems has memory limitations too, so you should have mongo running on a 64-bit processor and not on 32-bit.
Furthermore, since version 3.0 MongoDB has not commercial support for 32bit platforms; and starting in MongoDB 3.2, 32-bit binaries are deprecated and will be unavailable in future releases.

32bit/64bit
disk
CPU
...

### Testing
...

### Monitoring
...

### Keep current with versions

Keep your version of MongoDB current. Each release has significant performance enhancements, improvements and fixes.

## Storage Engine

This component is responsible of managing how data is stored, both in memory and on disk. There are many storage engines that you can choose to adapt to your application with the purpose of obtaining an improvement of performance.
In MongoDB 3.2 the default storage engine is WiredTiger. It provides a document-level concurrency model, checkpointing, compression and other features. On lower versions the default storage engine is MMAPv1, which works well with high volumes of reads and writes, as well as in place updates.


### WiredTiger Storage Engine

WiredTiger designed to maximize the performance of multi-core hardware and minimize the disk access thanks to the use of a compact file format and data compression. It provides a set of utilities for storage, which are detailed below:

####Document level concurrency

WiredTiger uses document-level concurrency control for write operations. As a result, multiple clients can modify different documents of a collection at the same time, Which substantially increases the performance of MongoDB.

For most read and write operations, WiredTiger uses optimistic concurrency control. WiredTiger uses only intent locks at the global, database and collection levels. When the storage engine detects conflicts between two operations, one will incur a write conflict causing MongoDB to transparently retry that operation.

####Snapshots and Checkpoints

WT provides a MultiVersion Concurrency Control (MVCC) that uses a point-in-time snapshot of the data to present a consistent view of the in-memory data.

When a write operation arrives, WT writes all data in a snapshot to disk. This data now acts as a checkpoint that ensures the data files are consistent up to and including the last checkpoint. This makes possible that a checkpoint can be used for recovering purposes. MongoDB configures WT to create checkpoints at intervals of 60 seconds or 2 gigabytes of journal data.

The new checkpoint becomes accessible and permanent when WiredTiger’s metadata table is atomically updated to reference the new checkpoint. Once the new checkpoint is accessible, WT frees pages from the old checkpoints.

You can recover from the last checkpoint using WT, but all the data written since the last checkpoint will be lost. To can recovery this data you must to use journaling.

####Journal

WT uses a write-ahead transaction log in combination with checkpoints to ensure data durability. WT uses journaling to persist all write operations between checkpoints. The journal is compressed using snappy library.
Journaling is important for standalone instances to avoid losing data when Mongo falls down between checkpoints. It isn’t as critical for replica set members because the replication process provides sufficient durability for our data.

####Compression

WT uses block compression with the snappy library for all collections and a prefix compression for all indexes. We can use for collections the zlib compression library too. Compression settings are also configurable on a per-collection and per-index basis during collection and index creation.

####Memory use

With WT, Mongo uses the internal cache of WT and the filesystem cache. The WT cache uses a 60% of RAM minus 1 GB or 1GB, whichever is larger.


### MMAPv1 Storage Engine

MMAPv1 is MongoDB’s original storage engine based on memory mapped files. It excels at workloads with high volume inserts, reads, and in-place updates.

####Journal

MongoDB, by default, records all modifications to an on-disk journal. MongoDB writes more frequently to the journal than it writes the data files (MongoDB writes to the data files on disk every 60 seconds and writes to the journal files roughly every 100 milliseconds).
The journal allows MongoDB to successfully recover data from data files after a mongod instance exits without flushing all changes.

####Record Storage Characteristics

All records are contiguously located on disk, and when a document becomes larger than the allocated record, MongoDB must allocate a new record.

New allocations require MongoDB to move a document and update all indexes that refer to the document, which takes more time than in-place updates and leads to storage fragmentation. To avoid this situation we can use two different record allocation strategies:

* __Power of 2 sized allocations__: Because documents in MongoDB may grow after insertion and all records are contiguous on disk, the padding can reduce the need to relocate documents on disk following updates. Relocations are less efficient than in-place updates and can lead to storage fragmentation. As a result, all padding strategies trade additional space for increased efficiency and decreased fragmentation.

   With the power of 2 sizes allocation strategy, each record has a size in bytes that is a power of 2 (e.g. 32, 64, 128, 256, 512 ... 2    MB). For documents larger than 2 MB, the allocation is rounded up to the nearest multiple of 2 MB.  
   This allows the document to grow without having to reallocate it and to reduce fragmentation, because a new document can reuse freed    records.

   This strategy works more efficient for insert/update/delete workloads.

* __No padding allocation__: This strategy can be used for collections whose workloads do not change the document sizes, such as workloads that consist of insert-only operations or update operations that do not increase document size.

####Memory use

MMAPv1 uses all free memory on the machine as its cache. System resource monitors show that MongoDB uses a lot of memory, but its usage is dynamic. If another process suddenly needs half the server’s RAM, MongoDB will yield cached memory to the other process.
Technically, the operating system’s virtual memory subsystem manages MongoDB’s memory. This means that MongoDB will use as much free memory as it can, swapping to disk as needed. Deployments with enough memory to fit the application’s working data set in RAM will achieve the best performance.


### In-Memory Storage Engine

The in-memory storage engine is part of general availability (GA) in the 64-bit builds. This kind of memory doesn't persist the data on disk, including configuration data, indexes, user credentials, etc.

By avoiding disk I/O, the in-memory storage engine allows for more predictable latency of database operations.

####Concurrency

The in-memory storage engine uses document-level concurrency control for write operations. As a result, multiple clients can modify different documents of a collection at the same time.

####Memory use

By default, the in-memory storage engine uses 50% of physical RAM minus 1 GB.

####Durability

The in-memory storage engine is non-persistent and does not write data to a persistent storage. That is non-persisted data includes application data and system data, such as users, permissions, indexes, replica set configuration, sharded cluster configuration, etc.
As such, the concept of journal or waiting for data to become durable does not apply to the in-memory storage engine.

Write operations that specify a write concern journaled are acknowledged immediately. When a mongod instance shuts down, either as result of the shutdown command or due to a system error, recovery of in-memory data is impossible.

## CRUD

MongoDB provides a series of commands to perform operations of create, delete, query and update documents. These operations are summarized below:

### Create documents

This operation creates a document into a collection given. If the collection does not currently exist, insert operations will create the collection. When a document is created, each document stored in a collection requires a unique _id field that acts as a primary key. If an inserted document omits the _id field, the MongoDB driver automatically generates an ObjectId for the _id field. All write operations in MongoDB are atomic on the level of a single document.

MongoDB provides the following methods for inserting documents into a collection:

### db.collection.insertOne()

This operation inserts a single document into a collection.

````json
db.getCollection('zips').insertOne({_id:"28015", city:"Madrid", loc:[40.418889,-3.691944], pop:6543031})
````

### db.collection.insertMany()

It inserts a set of documents into a collection. These documents are informed within an array:

````json
	db.getCollection('zips').insertMany([{"_id":"27001","city":"Lugo","loc":[43.011667,-7.557222],"pop":98134},
  	{"_id":"27002","city":"Lugo","loc":[43.011667,-7.557222],"pop":98134},
  	{"_id":"27003","city":"Lugo","loc":[43.011667,-7.557222],"pop":98134},
  	{"_id":"27004","city":"Lugo","loc":[43.011667,-7.557222],"pop":98134}])
````

### db.collection.insert() 

This operation inserts a single document or multiple documents into a collection. To insert a single document, pass a document to the method; to insert multiple documents, pass an array of documents to the method.

````json
db.getCollection('zips').insert({_id:"28015", city:"Madrid", loc:[ 40.418889,-3.691944], pop: 6543031})
````

````json
db.getCollection('zips').insert([{"_id":"27001","city":"Lugo","loc":[43.011667,-7.557222],"pop":98134},
 	{"_id":"27002","city":"Lugo","loc":[43.011667,-7.557222],"pop":98134},
  {"_id":"27003","city":"Lugo","loc":[43.011667,-7.557222],"pop":98134},
  {"_id":"27004","city":"Lugo","loc":[43.011667,-7.557222],"pop":98134}])
````

First of all, don’t worry about the data modeling of the examples. No matter if the collection zips is modeled appropriately.

On the other hand, you should bear in mind that there are other forms of creation of documents in a collection. The updates operations with the option upsert with a true value persists the documents if they don’t exist. 


## Read documents


## Update documents


## Delete documents

Delete operations do not drop indexes, even if deleting all documents from a collection. All write operations in MongoDB are atomic on the level of a single document. MongoDB provides the following methods for document elimination:

### db.collection.remove()

The db.collection.remove() method can have one of two syntaxes. The remove() method can take a query document and an optional justOne boolean.

````json
  db.collection.remove(
      <query>,
      <justOne>
  )
````

Or the method can take a query document and an optional remove options document:

````json
  db.collection.remove(
    <query>,
	   {
	     justOne: <boolean>,
	     writeConcern: <document>
	   }
	 )
````

And here we have an example:

````json
	db.products.remove(
	   { qty: { $gt: 20 } },
	   {justOne:true, writeConcern: {w:"majority", wtimeout:5000 } }
  )
````

### db.collection.deleteOne()

This operation removes a single document from a collection. deleteOne deletes the first document that matches the filter, so you must use a field that is part of a unique index such as _id for precise deletions.

````json
  db.collection.deleteOne(
	   <filter>,
	   {
	      writeConcern: <document>
	   }
 	)
````

And here we have examples:

````json
db.orders.deleteOne( { "productCode" : "78452dfa25564l") } );
````

````json
 	db.orders.deleteOne(
    { "_id" : ObjectId("563237a41a4d68582c2509da") },
       { w : "majority", wtimeout : 100 }
  );
````

### db.collection.deleteMany()

This method removes all documents that match the filter from a collection.

````json
	db.collection.deleteMany(
	   <filter>,
	   {
	      writeConcern: <document>
	   }
	)
````

````json
db.orders.deleteMany( { "stock" : "Brent Crude Futures", "limit" : { $gt : 48.88 } } );
````

## References

* [MongoDB documentation](https://docs.mongodb.com/manual/)
